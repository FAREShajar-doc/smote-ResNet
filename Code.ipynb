{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOa0KeSnPPxWKYmj3xV5VSO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nGRcD8EWL5lZ"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","import joblib\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Load the dataset\n","folder_path = \"/content/WSN-DS.csv\"\n","dataset = pd.read_csv(folder_path)\n","\n","# Prepare features and target variable\n","X = dataset.drop(['Attack type'], axis=1)\n","Y = dataset['Attack type']\n"]},{"cell_type":"code","source":[],"metadata":{"id":"BRrem2fvMV5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove spaces from the beginning of the column names\n","data.columns = data.columns.str.lstrip()\n","# rename the Attack type column to label\n","data.rename(columns={'Attack type': 'label'}, inplace=True)\n"," data.drop(['id', 'send_code '], axis=1, inplace=True)\n","  data.isnull().sum() # check for missing values it gave 0 for all columns\n","data.drop_duplicates(inplace=True) # remove duplicates it removed 8,873 rows\n"],"metadata":{"id":"VSFI3wCEMVe7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = data.drop('label', axis=1)\n","y = data['label']\n","class_counts = {'Normal': 332040, 'Grayhole': 13909, 'Blackhole': 10049, 'TDMA':\n","6633, 'Flooding': 3157}\n","# Calculate the number of samples we want for each class\n","target = min(class_counts.values()) * 10\n","# Upsample strategies\n","sampling_strategy_up = {k: target for k, v in class_counts.items() if v < target}\n","# Downsample strategies\n","sampling_strategy_down = {k: target for k, v in class_counts.items() if v >\n","target}\n","print(\"Upsample strategies:\", sampling_strategy_up)#{'Grayhole': 31570,\n","'Blackhole': 31570, 'TDMA': 31570, 'Flooding': 31570}\n","print(\"Downsample strategies:\", sampling_strategy_down)#{'Normal': 31570}\n"," 3 / 25\n","\n"," # Define the resampling pipeline\n","resample_pipeline = Pipeline([\n","    ('smote', SMOTE(sampling_strategy=sampling_strategy_up, random_state=42)),\n","    ('under', RandomUnderSampler(sampling_strategy=sampling_strategy_down,\n","random_state=42))\n","])\n","# Apply the resampling\n","X_resampled, y_resampled = resample_pipeline.fit_resample(X, y)"],"metadata":{"id":"OLvy-WRpMqKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nveQn7RtRiSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # scaling the data\n","scaler = MinMaxScaler()\n","X_resampled = scaler.fit_transform(X_resampled)\n","# save scaller for later use\n"," with open('later-use/scaler.pkl', 'wb') as file:\n","    pickle.dump(scaler, file)"],"metadata":{"id":"5Auh7JI4RhXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # spliting data\n"," X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled,\n","test_size=0.2, random_state=42)"],"metadata":{"id":"tL5L3tnFRjYn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" def evaluate_model(model,title, X_test, y_test):\n","    score = model.score(X_test, y_test)\n","    print(f'{title} Accuracy: {score}')\n","    y_pred = model.predict(X_test)\n","    print(f'{title} Classification Report: \\n', classification_report(y_test,\n","y_pred))"],"metadata":{"id":"dAZCi1XORvOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" def residual_block(x, filters, kernel_size=3):\n","    y = Conv1D(filters, kernel_size, padding='same')(x)\n","    y = BatchNormalization()(y)\n","    y = ReLU()(y)\n","    y = Conv1D(filters, kernel_size, padding='same')(y)\n","    y = BatchNormalization()(y)\n","    out = Add()([x, y])\n","    out = ReLU()(out)\n","return out\n","def ResNet1D(input_shape, num_classes):\n","    inputs = Input(shape=input_shape)\n","    x = Conv1D(64, 7, padding='same')(inputs)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","    x = MaxPooling1D(3)(x)\n","    x = residual_block(x, 64)\n","\n","\n","    x = residual_block(x, 64)\n","    x = GlobalAveragePooling1D()(x)\n","    outputs = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n","metrics=['accuracy'])\n","return model\n","\n"," ResNet1D_model = ResNet1D(input_shape, num_classes)\n","metrics_history_ResNet1D = MetricsHistory(val_data)\n","# models summary\n","print('ResNet1D_model summary:')\n","ResNet1D_model.summary()\n","# train the models\n","ResNet1D_model.fit(X_train_reshaped, y_train_encoded, epochs=10,batch_size=64,\n","validation_data=val_data, callbacks=[metrics_history_ResNet1D])\n","evaluate_deep_model(ResNet1D_model, 'ResNet1D', X_test_reshaped, y_test_encoded)"],"metadata":{"id":"Zom_sE7IR9Fl"},"execution_count":null,"outputs":[]}]}